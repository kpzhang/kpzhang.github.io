{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"758-Lab-2-answer.ipynb","provenance":[{"file_id":"1ZDPvTTtM9sPw0C5_E_xiVCyKDph5j4J4","timestamp":1604012101736}],"collapsed_sections":[],"authorship_tag":"ABX9TyPbrkauNi28nfmQpPv696rs"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"JsbtRr_3J28L","executionInfo":{"status":"ok","timestamp":1604010717535,"user_tz":240,"elapsed":22209,"user":{"displayName":"Kunpeng Zhang","photoUrl":"","userId":"09274433828486852799"}},"outputId":"683a9ca8-2be0-49f4-e890-b16c91e0eca4","colab":{"base_uri":"https://localhost:8080/"}},"source":["from google.colab import files,drive\n","\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"j8Ew-kI6LeU5","executionInfo":{"status":"ok","timestamp":1604012047090,"user_tz":240,"elapsed":439,"user":{"displayName":"Kunpeng Zhang","photoUrl":"","userId":"09274433828486852799"}},"outputId":"4e75acab-99a9-418e-8c9e-c1087c3c899f","colab":{"base_uri":"https://localhost:8080/"}},"source":["import torch\n","import torch.nn as nn \n","import torch.nn.functional as F \n","\n","device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n","\n","class Net(nn.Module):\n","\n","  def __init__(self):\n","\n","    super().__init__()\n","\n","    self.conv1 = nn.Conv2d(1,6,5)\n","    self.conv2 = nn.Conv2d(6,16,(5,5))\n","    self.pool = nn.MaxPool2d(2,2)\n","    self.fc1 = nn.Linear(16*4*4,120)\n","    self.fc2 = nn.Linear(120,84)\n","    self.fc3 = nn.Linear(84,10)\n","\n","  def forward(self, x):\n","    \n","    x = self.pool(F.relu(self.conv1(x)))\n","    x = self.pool(F.relu(self.conv2(x)))\n","    x = x.view(-1,self.num_flat_features(x))\n","    x = F.relu(self.fc1(x))\n","    x = F.relu(self.fc2(x))\n","    x = F.log_softmax(self.fc3(x))\n","\n","    return x\n","\n","  def num_flat_features(self,x):\n","    size = x.size()[1:] \n","    num_features = 1\n","    for s in size:\n","      num_features *= s\n","\n","    return num_features\n","\n","net = Net().to(device)\n","print(net)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Net(\n","  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n","  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n","  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  (fc1): Linear(in_features=256, out_features=120, bias=True)\n","  (fc2): Linear(in_features=120, out_features=84, bias=True)\n","  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",")\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"wtUiX4UpRlUj"},"source":["import os\n","import glob\n","import numpy as np  \n","from skimage import io \n","\n","from torch.utils.data import Dataset, DataLoader\n","\n","class MNISTDataset(Dataset):\n","\n","  def __init__(self, dir, transform=None):\n","    self.dir = dir # /content/drive/My Drive/BigDataAI/datasets/MNIST/trainingset/1/\n","    self.transform = transform\n","\n","  def __len__(self):\n","    files = glob.glob(self.dir+'/*.jpg')[:100] # return a list of file names in a given folder \n","    return len(files)\n","\n","  def __getitem__(self, idx):\n","    if torch.is_tensor(idx):\n","      idx = idx.tolist()\n","\n","    all_files = glob.glob(self.dir+'/*.jpg')[:100]\n","    img_fname = os.path.join(self.dir, all_files[idx])\n","    image = io.imread(img_fname) # numpy array of that particular image\n","\n","    digit = int(self.dir.split('/')[-1].strip())\n","    label = np.array(digit)\n","\n","    instance = {'image':image,'label':label}\n","\n","    if self.transform:\n","      instance = self.transform(instance)\n","\n","    return instance\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"s7j2RjG2URLU"},"source":["from skimage import transform\n","\n","class Rescale(object):\n","\n","  def __init__(self, output_size):\n","    assert isinstance(output_size, (int, tuple))\n","    self.output_size = output_size\n","\n","  def __call__(self, sample):\n","    image, label = sample['image'], sample['label']\n","\n","    h, w = image.shape[-2:]\n","    if isinstance(self.output_size, int):\n","      if h > w:\n","        new_h, new_w = self.output_size*h/w, self.output_size\n","      else:\n","        new_h, new_w = self.output_size, self.output_size*w/h\n","    else:\n","      new_h, new_w = self.output_size\n","\n","    new_h, new_w = int(new_h), int(new_w)\n","\n","    new_image = transform.resize(image, (new_h, new_w))\n","\n","    return {'image': new_image, 'label':label}\n","\n","class ToTensor(object):\n","\n","  def __call__(self, sample):\n","\n","    image, label = sample['image'], sample['label']\n","\n","    image = image.reshape((1,image.shape[0],image.shape[1]))\n","\n","    return {'image':torch.from_numpy(image) ,'label': torch.from_numpy(label)}"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"88YcCqEqW9Ps","executionInfo":{"status":"ok","timestamp":1604012052575,"user_tz":240,"elapsed":996,"user":{"displayName":"Kunpeng Zhang","photoUrl":"","userId":"09274433828486852799"}},"outputId":"77fcdca5-11e7-411d-c422-ddeb1bf4e695","colab":{"base_uri":"https://localhost:8080/"}},"source":["from torch.utils.data import random_split\n","from torchvision import transforms, utils\n","\n","batch_size = 32\n","\n","list_datasets = []\n","for i in range(10):\n","  cur_ds = MNISTDataset('/content/drive/My Drive/BigDataAI/datasets/MNIST/trainingset/'+str(i),transform=transforms.Compose([Rescale(28),ToTensor()]))\n","  list_datasets.append(cur_ds)\n","\n","dataset = torch.utils.data.ConcatDataset(list_datasets)\n","print(len(dataset))\n","\n","train_size = int(len(dataset)*0.7)\n","val_size = len(dataset) - train_size\n","train_dataset, val_dataset = random_split(dataset,[train_size, val_size])\n","\n","train_dataloader = DataLoader(train_dataset,batch_size,shuffle=True,num_workers=1)\n","val_dataloader = DataLoader(val_dataset,batch_size,shuffle=True,num_workers=1)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["1000\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"MiYMxfXmZkwV","outputId":"ed883f3c-b84f-45f0-a429-5b1d71e49b42","colab":{"base_uri":"https://localhost:8080/"}},"source":["import torch.optim as optim\n","\n","epochs = 5\n","learning_rate = 1e-4\n","optimizer = optim.Adam(net.parameters(),lr=learning_rate)\n","criterion = nn.CrossEntropyLoss()\n","\n","for epoch in range(epochs):\n","\n","  net.train()\n","\n","  running_loss = 0.0\n","  for b, batch in enumerate(train_dataloader):\n","    inputs, targets = batch['image'].to(device,dtype=torch.float), batch['label'].to(device,dtype=torch.long)\n","\n","    optimizer.zero_grad()\n","    outputs = net(inputs)\n","    loss = criterion(outputs,targets)\n","    loss.backward()\n","    optimizer.step()\n","\n","    if (b+1)%10 == 0:\n","      print('epoch: %d, batch: %d, training loss: %.3f' % (epoch+1, b+1, running_loss/10))\n","      running_loss = 0.0\n","\n","\n","  net.eval()\n","\n","  correct = [0.0]*10\n","  total = [0.0]*10\n","\n","  with torch.no_grad():\n","    for b, batch in enumerate(val_dataloader):\n","      inputs, labels = batch['image'].to(device,dtype=torch.float), batch['label'].to(device,dtype=torch.long)\n","\n","      predicted_outputs = net(inputs)\n","      _,predicted_idx = torch.max(predicted_outputs,1)\n","      c = (predicted_idx == labels)\n","      for i in range(len(labels)):\n","        label = labels[i]\n","        correct[label] += c[i].item()\n","        total[label] += 1\n","\n","  for i in range(10):\n","    print('\\t Validation accuracy for digit %d: %.3f'% (i, 100*correct[i]/total[i]))\n","\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:27: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"],"name":"stderr"}]}]}